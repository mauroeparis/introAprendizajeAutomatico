{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1: Regresión en Boston\n",
    "\n",
    "En este laboratorio deben hacer experimentos de regresión con el conjunto de datos \"Boston house prices dataset\".\n",
    "\n",
    "Estudiarán el dataset, harán visualizaciones y seleccionarán atributos relevantes a mano.\n",
    "\n",
    "Luego, entrenarán y evaluarán diferentes tipos de regresiones, buscando las configuraciones que mejores resultados den."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Conjunto de Datos\n",
    "\n",
    "Cargamos el conjunto de datos y vemos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en Entrenamiento y Evaluación\n",
    "\n",
    "Dividimos aleatoriamente los datos en 80% para entrenamiento y 20% para evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = boston['data'], boston['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responda las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponibles para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que serán los más determinantes para la predicción?\n",
    "5. ¿Qué problemas observa a priori en el conjunto de datos? ¿Observa posibles sesgos, riesgos, dilemas éticos, etc? Piense que los datos pueden ser utilizados para hacer predicciones futuras.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Es un conjunto de datos de inmuebles en suburbios de Boston, con precios de los inmuebles y otras características.\n",
    "13 Atributos y 506 instancias, es decir, 506 suburbios.\n",
    "\n",
    "2- Según la información que encontramos en internet, este conjunto de datos tiene principalmente dos objetivos de predicción: los niveles de óxido nitroso y el valor medio de vivienda.\n",
    "\n",
    "3- Hay 14 atributos disponibles:\n",
    "- **CRIM**:     per capita crime rate by town\n",
    "- **ZN**:       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- **INDUS**:    proportion of non-retail business acres per town\n",
    "- **CHAS**:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- **NOX**:      nitric oxides concentration (parts per 10 million)\n",
    "- **RM**:       average number of rooms per dwelling\n",
    "- **AGE**:      proportion of owner-occupied units built prior to 1940\n",
    "- **DIS**:      weighted distances to five Boston employment centres\n",
    "- **RAD**:      index of accessibility to radial highways\n",
    "- **TAX**:      full-value property-tax rate per USS10.000\n",
    "- **PTRATIO**:  pupil-teacher ratio by town\n",
    "- **B**:        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- **LSTAT**:    % lower status of the population\n",
    "- **MEDV**     Median value of owner-occupied homes in $1000\n",
    "\n",
    "4- Suponemos que los atributos determinantes pueden ser:\n",
    "- La tasa de criminalidad per capita por ciudad (CRIM)\n",
    "- Proporción de areas residenciales (ZN)\n",
    "- Distancias ponderadas a los centros de Boston (DIS)\n",
    "- Índice de acceso a rutas (RAD)\n",
    "- Tasa de impuesto a la propiedad (TAX)\n",
    "- Valor medio de viviendas ocupadas por sus dueños (MEDV)\n",
    "- Niveles de óxido nítrico (NOX)\n",
    "\n",
    "5- En principio encontramos que carece de varios datos relevantes para predecir el precio de una propiedad, tales como:\n",
    "- m2 techados de la propiedad\n",
    "- m2 de espacio abierto (sin techar, Ejemplo: jardín, balcón, etc)\n",
    "- tipo de inmueble (Ejemplo: departamento, casa, dúplex, piso, semipiso)\n",
    "- cantidad de habitaciones\n",
    "- cantidad de baños\n",
    "- antigüedad de la propiedad\n",
    "\n",
    "Como dilema ético nos sorprendió que exista un atributo que mida la proporción de personas de color (afrodescendientes) en la zona.\n",
    "Esto puede ser dado por la segregación racial que estaba impuesta en Estados Unidos pero la existencia de este tipo de datos claramente sesga al modelo y puede sostener estereotipos que nos perjudican como sociedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Visualización de los Datos\n",
    "\n",
    "1. Para cada atributo de entrada, haga una gráfica que muestre su relación con la variable objetivo.\n",
    "2. Estudie las gráficas, identificando **a ojo** los atributos que a su criterio sean los más informativos para la predicción.\n",
    "3. Para ud., ¿cuáles son esos atributos? Lístelos en orden de importancia.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataframe = pd.DataFrame(X, columns=boston['feature_names'])\n",
    "X_dataframe[\"MEDV\"] = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "import seaborn\n",
    "\n",
    "seaborn.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "f, axes = plt.subplots(5, 3, figsize=(25, 20), sharex=False)\n",
    "seaborn.despine()\n",
    "f.suptitle(\"\")\n",
    "\n",
    "# Plots\n",
    "seaborn.scatterplot(X_dataframe.CRIM, X_dataframe.MEDV, ax=axes[0, 0])\n",
    "seaborn.scatterplot(X_dataframe.ZN, X_dataframe.MEDV, ax=axes[0, 1])\n",
    "seaborn.scatterplot(X_dataframe.INDUS, X_dataframe.MEDV, ax=axes[0, 2])\n",
    "seaborn.scatterplot(X_dataframe.CHAS, X_dataframe.MEDV, ax=axes[1, 0])\n",
    "seaborn.scatterplot(X_dataframe.NOX, X_dataframe.MEDV, ax=axes[1, 1])\n",
    "seaborn.scatterplot(X_dataframe.RM, X_dataframe.MEDV, ax=axes[1, 2])\n",
    "seaborn.scatterplot(X_dataframe.AGE, X_dataframe.MEDV, ax=axes[2, 0])\n",
    "seaborn.scatterplot(X_dataframe.DIS, X_dataframe.MEDV, ax=axes[2, 1])\n",
    "seaborn.scatterplot(X_dataframe.RAD, X_dataframe.MEDV, ax=axes[2, 2])\n",
    "seaborn.scatterplot(X_dataframe.TAX, X_dataframe.MEDV, ax=axes[3, 0])\n",
    "seaborn.scatterplot(X_dataframe.PTRATIO, X_dataframe.MEDV, ax=axes[3, 1])\n",
    "seaborn.scatterplot(X_dataframe.B, X_dataframe.MEDV, ax=axes[3, 2])\n",
    "seaborn.scatterplot(X_dataframe.LSTAT, X_dataframe.MEDV, ax=axes[4, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bajo nuestra consideración las variables:\n",
    "- Habitaciones por vivienda (RM)\n",
    "- Porcentaje de habitantes de clase baja (LSTAT)\n",
    "- Distancia a 5 centros de empleo (DIS)\n",
    "- Proporción de tierra residencial dividida en zonas para lotes de más de 25,000 pies cuadrados (ZN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Regresión Lineal\n",
    "\n",
    "1. Seleccione **un solo atributo** que considere puede ser el más apropiado.\n",
    "2. Instancie una regresión lineal de **scikit-learn**, y entrénela usando sólo el atributo seleccionado.\n",
    "3. Evalúe, calculando error cuadrático medio para los conjuntos de entrenamiento y evaluación.\n",
    "4. Grafique el modelo resultante, junto con los puntos de entrenamiento y evaluación.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se puede obtener un error en test menor a 50.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "feature = 'LSTAT'\n",
    "selector = (boston['feature_names'] == feature)\n",
    "\n",
    "X_train_f = X_train[:, selector]\n",
    "X_test_f = X_test[:, selector]\n",
    "\n",
    "X_train_f.shape, X_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression(fit_intercept=True)\n",
    "linear_model.fit(X_train_f, y_train)\n",
    "\n",
    "print(linear_model.coef_, linear_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_y_train = linear_model.predict(X_train_f) \n",
    "pred_y_test = linear_model.predict(X_test_f) \n",
    "\n",
    "train_error = mean_squared_error(y_train, pred_y_train)\n",
    "test_error = mean_squared_error(y_test, pred_y_test)\n",
    "\n",
    "print(f'Train error: {train_error:0.2}')\n",
    "print(f'Test error: {test_error:0.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('Coefficient of determination for training set prediction: %.2f'\n",
    "      % r2_score(y_train, pred_y_train))\n",
    "\n",
    "print('Coefficient of determination for testing set prediction: %.2f'\n",
    "      % r2_score(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "x_start = min(np.min(X_train_f), np.min(X_test_f))\n",
    "x_end = max(np.max(X_train_f), np.max(X_test_f))\n",
    "x = np.linspace(x_start, x_end, 200).reshape(-1, 1)\n",
    "\n",
    "plt.plot(X_train_f, pred_y_train, color=\"tomato\", label=\"modelo\")\n",
    "\n",
    "plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"train\")\n",
    "plt.scatter(X_test_f, y_test, facecolor=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "\n",
    "plt.title(feature)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. La regresión está bien teniendo en cuenta que es lineal. Como era de esperarse no es perfecta y no puede ajustarse a muchos de los puntos con precisión. Dada la distribución de los datos puede que una regresión polinomial de grado mayor a 1 se ajuste mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Regresión Polinomial\n",
    "\n",
    "En este ejercicio deben entrenar regresiones polinomiales de diferente complejidad, siempre usando **scikit-learn**.\n",
    "\n",
    "Deben usar **el mismo atributo** seleccionado para el ejercicio anterior.\n",
    "\n",
    "1. Para varios grados de polinomio, haga lo siguiente:\n",
    "    1. Instancie y entrene una regresión polinomial.\n",
    "    2. Prediga y calcule error en entrenamiento y evaluación. Imprima los valores.\n",
    "    3. Guarde los errores en una lista.\n",
    "2. Grafique las curvas de error en términos del grado del polinomio.\n",
    "3. Interprete la curva, identificando el punto en que comienza a haber sobreajuste, si lo hay.\n",
    "4. Seleccione el modelo que mejor funcione, y grafique el modelo conjuntamente con los puntos.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se pueden obtener errores en test menores a 40 e incluso a 35.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "pol_models = []\n",
    "degrees = range(10)\n",
    "for degree in degrees:\n",
    "    # train:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X_train_f, y_train)\n",
    "    \n",
    "    # predict:\n",
    "    y_train_pred = model.predict(X_train_f)\n",
    "    y_test_pred = model.predict(X_test_f)\n",
    "    \n",
    "    # evaluate:\n",
    "    train_error = mean_squared_error(y_train, y_train_pred)\n",
    "    test_error = mean_squared_error(y_test, y_test_pred)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)\n",
    "    \n",
    "    pol_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "plt.plot(degrees, train_errors, color=\"blue\", label=\"train\")\n",
    "plt.plot(degrees, test_errors, color=\"red\", label=\"test\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consideramos que a partir del modelo de grado 5 empieza a haber sobreajuste porque, si bien el error en el conjunto de entrenamiento es bajo, no es así de bajo en el conjunto de prueba. Para grados superiores a 5 el error en el conjunto de pruebas no desciende sino que se mantiene o crece. Sospechamos que hay sobreajuste en la medida en que crece la diferencia entre el error de entrenamiento y el error de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. El modelo de grado 4 es el que mejor funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_model = pol_models[4]\n",
    "\n",
    "pred_y_train_pol = pol_model.predict(X_train_f)\n",
    "pred_y_test_pol = pol_model.predict(X_test_f)\n",
    "\n",
    "train_error_pol = mean_squared_error(y_train, pred_y_train_pol)\n",
    "test_error_pol = mean_squared_error(y_test, pred_y_test_pol)\n",
    "print(f'Train error: {train_error_pol:0.2}')\n",
    "print(f'Test error: {test_error_pol:0.2}')\n",
    "\n",
    "plt.plot(sorted(X_train_f), sorted(pred_y_train_pol, reverse=True), color=\"tomato\", label=\"modelo\")\n",
    "\n",
    "plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"train\")\n",
    "plt.scatter(X_test_f, y_test, facecolor=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.title(feature)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. A simple vista podemos ver cómo la regresión polinomial se ajusta mucho mejor a la naturaleza real de los datos que la lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Regresión con más de un Atributo\n",
    "\n",
    "En este ejercicio deben entrenar regresiones que toman más de un atributo de entrada.\n",
    "\n",
    "1. Seleccione **dos o tres atributos** entre los más relevantes encontrados en el ejercicio 2.\n",
    "2. Repita el ejercicio anterior, pero usando los atributos seleccionados. No hace falta graficar el modelo final.\n",
    "3. Interprete el resultado y compare con los ejercicios anteriores. ¿Se obtuvieron mejores modelos? ¿Porqué?\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "selector = (boston['feature_names'] == 'RM') | (boston['feature_names'] == 'LSTAT')\n",
    "\n",
    "X_train_fs = X_train[:, selector]\n",
    "X_test_fs = X_test[:, selector]\n",
    "\n",
    "X_train_fs.shape, X_test_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "degree_m = 2\n",
    "mult_model = make_pipeline(PolynomialFeatures(degree_m), LinearRegression())\n",
    "\n",
    "mult_regresion = mult_model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predecir y evaluar\n",
    "pred_y_train_mult = mult_regresion.predict(X_train_fs) \n",
    "pred_y_test_mult = mult_regresion.predict(X_test_fs) \n",
    "\n",
    "train_error_mult = mean_squared_error(y_train, pred_y_train_mult)\n",
    "test_error_mult = mean_squared_error(y_test, pred_y_test_mult)\n",
    "\n",
    "print(f'Train error: {train_error_mult:0.2}')\n",
    "print(f'Test error: {test_error_mult:0.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_m = []\n",
    "test_errors_m = []\n",
    "degrees_2 = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for degree in degrees_2:\n",
    "    # train:\n",
    "    multi_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    mr = multi_model.fit(X_train_fs, y_train)\n",
    "    \n",
    "    # predict:\n",
    "    y_train_pred_m = mr.predict(X_train_fs)\n",
    "    y_test_pred_m = mr.predict(X_test_fs)\n",
    "    \n",
    "    # evaluate:\n",
    "    train_error = mean_squared_error(y_train, y_train_pred_m)\n",
    "    test_error = mean_squared_error(y_test, y_test_pred_m)\n",
    "    train_errors_m.append(train_error)\n",
    "    test_errors_m.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees_2, train_errors_m, color=\"blue\", label=\"train\")\n",
    "plt.plot(degrees_2, test_errors_m, color=\"red\", label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Disminuye el error cuadrático medio tanto para el conjunto de entrenamiento como para el conjunto de prueba. La incorporación de una segunda variable ayuda a que el modelo tengo una mayor capacidad de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más ejercicios (opcionales)\n",
    "\n",
    "### Ejercicio 7: A Todo Feature\n",
    "\n",
    "Entrene y evalúe regresiones pero utilizando todos los atributos de entrada (va a andar mucho más lento). Estudie los resultados.\n",
    "\n",
    "### Ejercicio 8: Regularización\n",
    "\n",
    "Entrene y evalúe regresiones con regularización \"ridge\". Deberá probar distintos valores de \"alpha\" (fuerza de la regularización). ¿Mejoran los resultados?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
